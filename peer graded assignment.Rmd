---
title: 'Peer-graded Assignment: Prediction Assignment Writeup'
author: "Wayne Tipton"
date: "January 7, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Executive Summary
The goal of this project is to predict if a person is performing a dumbell curl exercise properly using only the data collected from an on-body sensing approach.

# Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: <http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har> (see the section on the Weight Lifting Exercise Dataset).

# Building the model
### Model selection
I decided to use random forest model for this exercise because it has a reputation as being a good performer.  The variable classe was used to make predictions on.  

* classe variable
        
        + A - exercse performed correctly
        + B - throwing elbows to the front
        + C - lifing dumbbell halfway
        + D - lowering dumbbell halfway
        + E - throwing hips to front
        
The model is to predict classe A occurances.

### Cross validation
The training set is split 70% for training and 30% for testing.

### Model evalaution
The model will be evaluated by the confusion matrix:
Sensitivity - the true positive rate
Specificity - the true negative rate

### Install packages and load data.
Download data and place into working directory.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(caret)
library(dplyr)
train <- read.csv('pml-training.csv', na.strings = c("NA","#DIV/0!",""))
test <- read.csv('pml-testing.csv', na.strings = c("NA","#DIV/0!",""))
set.seed(101)
```
### Cleaning the data
there are a lot of missing values, so we will keep only the colums with 90% or greater data available.

```{r}
# keep columns that have 90% of the data, dropped 100 columns
train.noNA <- train[colSums(!is.na(train))>(nrow(train)*.9)]
test <- test[colSums(!is.na(test))>(nrow(test)*.9)]
print("Any missing training data?")
any(is.na(train.noNA))
print("Any missing test data?")
any(is.na(test))
```

Remove the first 7 columns because they are not needed for calculation.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# Remove the first 7 columns because they are not needed for calculation
train.clean <- train.noNA[,-c(1:7)]

```

Removing highly correlated predictors.

```{r}
# get only numeric columns
num.cols <-sapply(train.clean,is.numeric)
# make correlation matrix
cor.data <- cor(train.clean[,num.cols])
# identify correlated predictors for removal
high.cor <- findCorrelation(cor.data, cutoff = .75)
train.cor <- train.clean[,-high.cor]
train.cor$classe <-as.factor(train.cor$classe)
```

Split training set for cross validation.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# split train.cor into training and testing sets
inTrain <- createDataPartition(y=train.cor$classe,p=0.75,list=FALSE)
training <- train.cor[inTrain,]
testing <- train.cor[-inTrain,]
```

# Build random forest model

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# random forest
library(randomForest)
modelfit.rf <- randomForest(classe ~.,training)
```

### Predict on testing set

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# predict
pred.rf <- predict(modelfit.rf,testing)
```

### View confusion matrix
Based on the confusion matrix summary.
Sensitivity is .9986
Specificity is .9977
The balaced accuracy is .9981

```{r}
cmatrix <- confusionMatrix(pred.rf,testing$classe)
cmatrix
```

### View model fit
The model fit plot show that error drops from .15 to below .025 with 500 trees.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# plot model fit
plot(modelfit.rf)
```

# Final prediction
The random forrest model worked great. So we will use the model to predict our test set.

```{r}
final.pred <- predict(modelfit.rf, test, type = "class")
print(final.pred)

# add final predict to test set
test <- cbind(test,final.pred)

```



